{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline-lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOX/s1wu2NYCTUntfNdqE+c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErwSi3VfMDY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "26c75a11-2476-4c85-f516-8d72975db5df"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding, Input, Bidirectional\n",
        "from keras.layers import GlobalMaxPooling1D, SpatialDropout1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score\n",
        "from keras.utils import plot_model\n",
        "\n",
        "def metrics(predictions, y_test):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
        "    print(f'Verdaderos Negativos: {tn}')\n",
        "    print(f'Falsos Negativos: {fn}')\n",
        "    print(f'Verdaderos Positivos: {tp}')\n",
        "    print(f'Falsos Positivos: {fp}')\n",
        "    print()\n",
        "    print(f'precision score: {precision_score(y_test, predictions)}')\n",
        "    print(f'recall score: {recall_score(y_test, predictions)}')\n",
        "    print(f'f1 score: {f1_score(y_test,  predictions)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9vDNQpHM_mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "6f55c3dd-375e-4993-a0fa-045f7b28903e"
      },
      "source": [
        "!pip install gensim\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.33)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.33)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1WTjXfbNM-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "828e8c8f-11af-4439-9762-34ef534287fb"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "!wget -c http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip\n",
        "\n",
        "EMBEDDING_FILE = 'GoogleNews-vectors-negative300.bin.gz'\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-06 17:44:20--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.241.54\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.241.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2020-08-06 17:44:22--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2020-08-06 17:44:22--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2020-08-06 17:44:22--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yiqIp_tPWLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/fsicardir/datos-tp2/master/dataset/train.csv?token=AFVAIUW66UE3NA5X2SYXNPC7GHGJY'\n",
        "url_test = 'https://raw.githubusercontent.com/fsicardir/datos-tp2/master/dataset/test.csv?token=AFVAIUUSBVEOOMDIFV4GU6C7GHGNK'\n",
        "\n",
        "read_train = pd.read_csv(url_train)\n",
        "read_test = pd.read_csv(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhv3sLvXPbN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "a2806f78-2c24-43c0-8118-b346a55ec0b4"
      },
      "source": [
        "df_train = read_train[['id', 'text', 'target']]\n",
        "df_test = read_test[['id', 'text']]\n",
        "\n",
        "# Limpiamos los datos de la forma usual\n",
        "# Quitamos las urls\n",
        "df_train['text'] = df_train['text'].str.replace(r'http:\\/\\/.*', '', regex=True).replace(r'https:\\/\\/.*', '', regex=True)\n",
        "df_test['text'] = df_test['text'].str.replace(r'http:\\/\\/.*', '', regex=True).replace(r'https:\\/\\/.*', '', regex=True)\n",
        "\n",
        "# Quitamos user mentions, signos de puntuación, hashtags y stopwords.\n",
        "def clean_text(text):\n",
        "    words = text.lower().split(' ')\n",
        "    text = ' '.join([word for word in words if not word.startswith('@') and word not in stopwords.words('english')])\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(clean_text)\n",
        "df_test['text'] = df_test['text'].apply(clean_text)\n",
        "\n",
        "train_tweets = df_train['text'].tolist()\n",
        "train_target = df_train['target']\n",
        "test_tweets = df_test['text'].tolist()\n",
        "len(train_tweets), len(train_target), len(test_tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPiaW1S7Ph2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oov_token = \"<UNK>\"\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(train_tweets)\n",
        "vocabulary_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(train_tweets)\n",
        "sequence_test = tokenizer.texts_to_sequences(test_tweets)\n",
        "\n",
        "max_padding = 25\n",
        "padded_vecs_train = pad_sequences(sequences_train, maxlen=max_padding, padding='post')\n",
        "padded_vecs_test = pad_sequences(sequence_test, maxlen=max_padding, padding='post')\n",
        "\n",
        "# Ahora vamos a crear una matriz que tendrá los embeddings de Google\n",
        "# correspondientes a cada palabra de nuestro vocabulario.\n",
        "# Esto se lo pasaremos como pesos a la capa de Embedding del modelo a entrenar.\n",
        "embedding_dim_w2v = 300\n",
        "embedding_matrix_w2v = np.zeros((vocabulary_size, embedding_dim_w2v))\n",
        "oov_words_w2v = 0\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  try:\n",
        "    embedding_vector = word2vec[word]\n",
        "    embedding_matrix_w2v[i] = embedding_vector\n",
        "  except:\n",
        "    oov_words_w2v += 1\n",
        "    continue\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f9IhaNkg2Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargamos los embeddings de GloVe. Utilizaremos los de 200 dimensiones.\n",
        "glove_dict = {}\n",
        "with open('glove.twitter.27B.200d.txt') as f:\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      vector = np.asarray(values[1:], dtype='float32')\n",
        "      glove_dict[word] = vector\n",
        "\n",
        "oov_words_gl = 0\n",
        "embedding_dim_gl = 200\n",
        "embedding_matrix_gl = np.zeros((vocabulary_size, embedding_dim_gl))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = glove_dict.get(word, None)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_gl[i] = embedding_vector\n",
        "    else:\n",
        "      oov_words_gl += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LeX3u3xP_uR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e5620c7-1632-4c48-ded8-4367861d9789"
      },
      "source": [
        "vocabulary_size, oov_words_w2v, oov_words_gl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15404, 4608, 3406)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veof2jN-Qn4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6ac6c19-c779-47a9-e9d3-db4735d6128f"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_vecs_train, train_target, test_size=0.2, random_state=31)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6090, 25), (6090,), (1523, 25), (1523,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE0-u5aIhrpd",
        "colab_type": "text"
      },
      "source": [
        "Nuestro baseline va a ser un modelo simple, donde tenemos la siguiente arquitectura:\n",
        "\n",
        "* Capa de Embedding: vamos a probar tanto con w2v como con glove.\n",
        "* Capa LSTM: Dejamos fijo el unit_size en 64 porque nos dio resultados decentes en pruebas preliminares.\n",
        "* Capa Dense: La capa FC para interpretar la salida de la RNN de la capa previa, por default usaremos 32 neuronas ya que es un número recurrente en distintos tutoriales.\n",
        "* Capa Dropout: Para reducir un poco el overfit vamos a dejar una capa de Dropout configurable por parámetro. Por default será 0.\n",
        "* Capa Dense: Para hacer la predicción, una neurona, función de activación sigmoidea."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4vanzhPi87d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_layer_w2v =  Embedding(input_dim=vocabulary_size, output_dim=embedding_dim_w2v, weights=[embedding_matrix_w2v], input_length=max_padding, trainable=False)\n",
        "emb_layer_gl = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim_gl, weights=[embedding_matrix_gl], input_length=max_padding, trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6MYJTLhVCEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Como capa de Embedding default usaremos la de glove.\n",
        "def build_baseline(lstm_size=64, hidden_neurons=32, dropout_rate=0.0, emb_layer=emb_layer_gl):\n",
        "  model = Sequential()\n",
        "  model.add(emb_layer)\n",
        "  model.add(LSTM(lstm_size))\n",
        "  model.add(Dense(hidden_neurons, activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRRTdxDUnUST",
        "colab_type": "text"
      },
      "source": [
        "# Baseline + GloVe Twitter\n",
        "Primero vamos a usar los parámetros default y ver qué f1 score obtenemos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn2ED-p8nqLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu1e13ohnM6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "54cfe487-d795-4885-ca65-8c501b1e5316"
      },
      "source": [
        "model1 = build_baseline()\n",
        "model1.summary()\n",
        "model1.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model1.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 200)           3080800   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                67840     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 3,150,753\n",
            "Trainable params: 69,953\n",
            "Non-trainable params: 3,080,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 5s 24ms/step - loss: 0.5056 - accuracy: 0.7670 - val_loss: 0.4331 - val_accuracy: 0.8207\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 4s 21ms/step - loss: 0.4286 - accuracy: 0.8172 - val_loss: 0.4187 - val_accuracy: 0.8221\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 4s 19ms/step - loss: 0.4102 - accuracy: 0.8264 - val_loss: 0.4515 - val_accuracy: 0.8102\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 4s 19ms/step - loss: 0.3816 - accuracy: 0.8399 - val_loss: 0.4387 - val_accuracy: 0.8037\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 4s 20ms/step - loss: 0.3559 - accuracy: 0.8493 - val_loss: 0.4389 - val_accuracy: 0.8175\n",
            "WARNING:tensorflow:From <ipython-input-13-9460208a3e93>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Verdaderos Negativos: 772\n",
            "Falsos Negativos: 196\n",
            "Verdaderos Positivos: 473\n",
            "Falsos Positivos: 82\n",
            "\n",
            "precision score: 0.8522522522522522\n",
            "recall score: 0.7070254110612855\n",
            "f1 score: 0.7728758169934641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We7zQeOxpg4z",
        "colab_type": "text"
      },
      "source": [
        "Obtuvimos un puntaje decente a comparación de lo que observamos en los notebooks donde usamos CNNs sencillas, veamos a continuación cuánto cambia el resultado utilizando w2v."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQQDHG2bpyBO",
        "colab_type": "text"
      },
      "source": [
        "# Baseline + w2v"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arc6pY4mp05P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "bbbfe110-bdff-4990-d491-9ccad8df3a1c"
      },
      "source": [
        "model2 = build_baseline(emb_layer=emb_layer_w2v)\n",
        "model2.summary()\n",
        "model2.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model2.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 300)           4621200   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 4,716,753\n",
            "Trainable params: 95,553\n",
            "Non-trainable params: 4,621,200\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 5s 29ms/step - loss: 0.5042 - accuracy: 0.7580 - val_loss: 0.4418 - val_accuracy: 0.8050\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 5s 26ms/step - loss: 0.4329 - accuracy: 0.8140 - val_loss: 0.4338 - val_accuracy: 0.8129\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 5s 26ms/step - loss: 0.4188 - accuracy: 0.8163 - val_loss: 0.4360 - val_accuracy: 0.8043\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 5s 27ms/step - loss: 0.4075 - accuracy: 0.8268 - val_loss: 0.4506 - val_accuracy: 0.8096\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 5s 26ms/step - loss: 0.3963 - accuracy: 0.8346 - val_loss: 0.4373 - val_accuracy: 0.8188\n",
            "Verdaderos Negativos: 777\n",
            "Falsos Negativos: 199\n",
            "Verdaderos Positivos: 470\n",
            "Falsos Positivos: 77\n",
            "\n",
            "precision score: 0.8592321755027422\n",
            "recall score: 0.70254110612855\n",
            "f1 score: 0.7730263157894737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv4ILfSNquHe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Obtuvimos resultados similares para ambos embeddings.\n",
        "\n",
        "A continuación utilizaremos un unit size mayor para la capa LSTM, para ver si obtenemos mejores resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbWGBQHrrZ1J",
        "colab_type": "text"
      },
      "source": [
        "# Baseline + GloVe + mayor unit_size en LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjePV5a3reUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "0655525e-be43-439e-fcc8-ef09b4ea0e8c"
      },
      "source": [
        "model3 = build_baseline(lstm_size=128)\n",
        "model3.summary()\n",
        "model3.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model3.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 200)           3080800   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               168448    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 3,253,409\n",
            "Trainable params: 172,609\n",
            "Non-trainable params: 3,080,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 9s 47ms/step - loss: 0.4976 - accuracy: 0.7698 - val_loss: 0.4404 - val_accuracy: 0.8102\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 9s 48ms/step - loss: 0.4306 - accuracy: 0.8153 - val_loss: 0.4291 - val_accuracy: 0.8188\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 9s 49ms/step - loss: 0.4065 - accuracy: 0.8269 - val_loss: 0.4378 - val_accuracy: 0.8181\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 9s 47ms/step - loss: 0.3853 - accuracy: 0.8353 - val_loss: 0.4567 - val_accuracy: 0.8148\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 9s 46ms/step - loss: 0.3629 - accuracy: 0.8445 - val_loss: 0.4483 - val_accuracy: 0.8168\n",
            "Verdaderos Negativos: 773\n",
            "Falsos Negativos: 198\n",
            "Verdaderos Positivos: 471\n",
            "Falsos Positivos: 81\n",
            "\n",
            "precision score: 0.8532608695652174\n",
            "recall score: 0.7040358744394619\n",
            "f1 score: 0.7714987714987716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deyQhcfpsLIQ",
        "colab_type": "text"
      },
      "source": [
        "El F1 Score apenas empeoró, y no hay grandes cambios en el precision/recall.\n",
        "Ahora probaremos lo mismo pero con los otros embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIuxV-O4sf3p",
        "colab_type": "text"
      },
      "source": [
        "# Baseline + w2v + mayor unit_size en LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNMxxtTkslkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "07e814b5-80fc-4987-cb06-205f47c4d163"
      },
      "source": [
        "model4 = build_baseline(lstm_size=128, emb_layer=emb_layer_w2v)\n",
        "model4.summary()\n",
        "model4.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model4.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 300)           4621200   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 4,845,009\n",
            "Trainable params: 223,809\n",
            "Non-trainable params: 4,621,200\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 11s 57ms/step - loss: 0.4978 - accuracy: 0.7657 - val_loss: 0.4618 - val_accuracy: 0.7925\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 10s 52ms/step - loss: 0.4424 - accuracy: 0.8062 - val_loss: 0.4444 - val_accuracy: 0.8122\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 10s 54ms/step - loss: 0.4250 - accuracy: 0.8184 - val_loss: 0.4352 - val_accuracy: 0.8155\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 10s 55ms/step - loss: 0.4165 - accuracy: 0.8233 - val_loss: 0.4471 - val_accuracy: 0.8017\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 10s 53ms/step - loss: 0.4012 - accuracy: 0.8317 - val_loss: 0.4453 - val_accuracy: 0.8024\n",
            "Verdaderos Negativos: 708\n",
            "Falsos Negativos: 155\n",
            "Verdaderos Positivos: 514\n",
            "Falsos Positivos: 146\n",
            "\n",
            "precision score: 0.7787878787878788\n",
            "recall score: 0.7683109118086696\n",
            "f1 score: 0.7735139202407826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm1rWnK0tKC3",
        "colab_type": "text"
      },
      "source": [
        "No vemos una mejora notoria en el F1 Score.\n",
        "\n",
        "Perdimos precision pero ganamos un 6% en recall.\n",
        "\n",
        "De momento dejaremos fijo este tamaño para LSTM y ahora probaremos con otra cantidad de neuronas en la capa densa.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr2-71kZtipa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_SIZE = 128\n",
        "HIDDEN_NEURONS = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyIqZP2Vtbgb",
        "colab_type": "text"
      },
      "source": [
        "# Baseline + GloVe Twitter + más hidden neurons\n",
        "\n",
        "Intentaremos un salto agresivo, usaremos el cuadruple de neuronas ocultas y veremos qué pasa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpVQisp2ta2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "462b5223-b6de-4050-8941-aa987008e778"
      },
      "source": [
        "model5 = build_baseline(lstm_size=LSTM_SIZE, hidden_neurons=HIDDEN_NEURONS)\n",
        "model5.summary()\n",
        "model5.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model5.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 200)           3080800   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               168448    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,315,809\n",
            "Trainable params: 235,009\n",
            "Non-trainable params: 3,080,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 10s 51ms/step - loss: 0.4812 - accuracy: 0.7829 - val_loss: 0.4740 - val_accuracy: 0.8024\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 9s 49ms/step - loss: 0.4298 - accuracy: 0.8108 - val_loss: 0.4621 - val_accuracy: 0.8102\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 9s 49ms/step - loss: 0.4044 - accuracy: 0.8259 - val_loss: 0.4314 - val_accuracy: 0.8135\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 9s 48ms/step - loss: 0.3802 - accuracy: 0.8355 - val_loss: 0.4426 - val_accuracy: 0.8109\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 10s 53ms/step - loss: 0.3591 - accuracy: 0.8470 - val_loss: 0.4713 - val_accuracy: 0.8142\n",
            "Verdaderos Negativos: 723\n",
            "Falsos Negativos: 152\n",
            "Verdaderos Positivos: 517\n",
            "Falsos Positivos: 131\n",
            "\n",
            "precision score: 0.7978395061728395\n",
            "recall score: 0.772795216741405\n",
            "f1 score: 0.7851176917236143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFgNLWkN10NN",
        "colab_type": "text"
      },
      "source": [
        "# Baseline + w2v + más hidden neurons\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuLivNZkuBXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "b6bdb439-5447-474a-cbf3-b40503237eff"
      },
      "source": [
        "model6 = build_baseline(lstm_size=LSTM_SIZE, hidden_neurons=HIDDEN_NEURONS, emb_layer=emb_layer_w2v)\n",
        "model6.summary()\n",
        "model6.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model6.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 300)           4621200   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 4,907,409\n",
            "Trainable params: 286,209\n",
            "Non-trainable params: 4,621,200\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 11s 59ms/step - loss: 0.4845 - accuracy: 0.7831 - val_loss: 0.4545 - val_accuracy: 0.8011\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 11s 55ms/step - loss: 0.4460 - accuracy: 0.8095 - val_loss: 0.4636 - val_accuracy: 0.7984\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 11s 55ms/step - loss: 0.4265 - accuracy: 0.8220 - val_loss: 0.4398 - val_accuracy: 0.8109\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 11s 56ms/step - loss: 0.4056 - accuracy: 0.8276 - val_loss: 0.4795 - val_accuracy: 0.8083\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 11s 56ms/step - loss: 0.3927 - accuracy: 0.8351 - val_loss: 0.4410 - val_accuracy: 0.8155\n",
            "Verdaderos Negativos: 737\n",
            "Falsos Negativos: 164\n",
            "Verdaderos Positivos: 505\n",
            "Falsos Positivos: 117\n",
            "\n",
            "precision score: 0.8118971061093248\n",
            "recall score: 0.7548579970104634\n",
            "f1 score: 0.7823392718822618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfjCs5xsuo-z",
        "colab_type": "text"
      },
      "source": [
        "En ambos casos llegamos a 0.78 de F1 Score por lo que mejoró un poco el modelo. Vamos a probar agregar un poco de regularización por medio de la capa de Dropout con la que cuenta el modelo base."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjDV4pNHvUlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "8ef2b92e-e2e1-40cc-90b2-4a727a5cac20"
      },
      "source": [
        "model7 = build_baseline(lstm_size=LSTM_SIZE, hidden_neurons=HIDDEN_NEURONS, dropout_rate=0.25)\n",
        "model7.summary()\n",
        "model7.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model7.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 25, 200)           3080800   \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 128)               168448    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,315,809\n",
            "Trainable params: 235,009\n",
            "Non-trainable params: 3,080,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 10s 50ms/step - loss: 0.4963 - accuracy: 0.7785 - val_loss: 0.4367 - val_accuracy: 0.8201\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 9s 49ms/step - loss: 0.4329 - accuracy: 0.8128 - val_loss: 0.4274 - val_accuracy: 0.8155\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 10s 51ms/step - loss: 0.4107 - accuracy: 0.8299 - val_loss: 0.4279 - val_accuracy: 0.8155\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 9s 48ms/step - loss: 0.3823 - accuracy: 0.8445 - val_loss: 0.4415 - val_accuracy: 0.8096\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 10s 50ms/step - loss: 0.3595 - accuracy: 0.8504 - val_loss: 0.4413 - val_accuracy: 0.8109\n",
            "Verdaderos Negativos: 720\n",
            "Falsos Negativos: 154\n",
            "Verdaderos Positivos: 515\n",
            "Falsos Positivos: 134\n",
            "\n",
            "precision score: 0.7935285053929122\n",
            "recall score: 0.7698056801195815\n",
            "f1 score: 0.7814871016691959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pl-p-CBvfwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "1913345c-fceb-4e01-c9cd-138fde016d17"
      },
      "source": [
        "model8 = build_baseline(lstm_size=LSTM_SIZE, hidden_neurons=HIDDEN_NEURONS, emb_layer=emb_layer_w2v, dropout_rate=0.25)\n",
        "model8.summary()\n",
        "model8.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
        "preds = model8.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 300)           4621200   \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 4,907,409\n",
            "Trainable params: 286,209\n",
            "Non-trainable params: 4,621,200\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "191/191 [==============================] - 11s 58ms/step - loss: 0.4947 - accuracy: 0.7668 - val_loss: 0.4501 - val_accuracy: 0.8050\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 10s 53ms/step - loss: 0.4417 - accuracy: 0.8133 - val_loss: 0.4360 - val_accuracy: 0.8116\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 10s 53ms/step - loss: 0.4269 - accuracy: 0.8176 - val_loss: 0.4328 - val_accuracy: 0.8116\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 11s 58ms/step - loss: 0.4116 - accuracy: 0.8236 - val_loss: 0.4512 - val_accuracy: 0.8004\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 10s 54ms/step - loss: 0.3949 - accuracy: 0.8330 - val_loss: 0.4892 - val_accuracy: 0.8037\n",
            "Verdaderos Negativos: 726\n",
            "Falsos Negativos: 171\n",
            "Verdaderos Positivos: 498\n",
            "Falsos Positivos: 128\n",
            "\n",
            "precision score: 0.7955271565495208\n",
            "recall score: 0.7443946188340808\n",
            "f1 score: 0.7691119691119692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOXVqASXVB4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N41vf-3HLE",
        "colab_type": "text"
      },
      "source": [
        "En el caso de w2v sufrimos una pérdida de poco más de 1% en el F1 Score.\n",
        "\n",
        "Mientras que en el caso de GloVe observamos se mantuvo casi igual el puntaje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0BHMhDXEAuE",
        "colab_type": "text"
      },
      "source": [
        "# Modelo de mayor complejidad\n",
        "\n",
        "Ahora probaremos agregar algunas capas extra para ver cómo se comporta un modelo un poco más complejo basado en RNNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ZUH8p336yr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "2d6cdc54-8fd2-498b-9c43-82047c651cbf"
      },
      "source": [
        "# Esta arquitectura es un frankestein al que se llegó sacando ideas de tutoriales como el de TensorFlow donde\n",
        "# recomiendan usar una capa Bidirectional para entrenar dos LSTMs, una que procesa los inputs en el orden que entran\n",
        "# y otra que lo hace a la inversa. Se supone que así se puede sacar mayor contexto del texto.\n",
        "# El SpatialDropout lo agregamos porque parece dar buenos resultados, así que no hay mucha más justificación que esa.\n",
        "\n",
        "# El mejor submit fue con 0.2, 128, 512 y 0.25 en los sigueintes cuatro parámetros. Las dos capas densas tenían la misma cantidad de neuronas.\n",
        "# Intento actual: modifiqué la cantidad de neuronas en la segunda capa densa.\n",
        "# También agregamos recurrent_dropout para ver qué efecto produce en el resultado.\n",
        "# Probaremos hacer un submit con este modelo y pasar a otras cosas.\n",
        "\n",
        "SPATIAL_DROPOUT = 0.2\n",
        "LTSM_SIZE = 128\n",
        "HIDDEN_NEURONS = 512\n",
        "DROPOUT = 0.5\n",
        "\n",
        "m = Sequential()\n",
        "m.add(emb_layer_w2v)\n",
        "m.add(SpatialDropout1D(SPATIAL_DROPOUT))\n",
        "m.add(Bidirectional(LSTM(LSTM_SIZE, return_sequences=True, recurrent_dropout=0.2)))\n",
        "m.add(GlobalMaxPooling1D())\n",
        "m.add(Dense(HIDDEN_NEURONS, activation='relu'))\n",
        "m.add(Dropout(DROPOUT))\n",
        "m.add(Dense(HIDDEN_NEURONS / 2, activation='relu'))\n",
        "m.add(Dropout(DROPOUT))\n",
        "m.add(Dense(1, activation='sigmoid'))\n",
        "m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 300)           4621200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 25, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 25, 256)           439296    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 5,323,665\n",
            "Trainable params: 702,465\n",
            "Non-trainable params: 4,621,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig3ghEo_4q-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "e5ad988d-945a-4bb6-e3b3-37ed0c80e80f"
      },
      "source": [
        "m.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 32s 168ms/step - loss: 0.5125 - accuracy: 0.7544 - val_loss: 0.4479 - val_accuracy: 0.8050\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 31s 164ms/step - loss: 0.4467 - accuracy: 0.8025 - val_loss: 0.4564 - val_accuracy: 0.7997\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 32s 169ms/step - loss: 0.4175 - accuracy: 0.8235 - val_loss: 0.4647 - val_accuracy: 0.7991\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 33s 172ms/step - loss: 0.3821 - accuracy: 0.8358 - val_loss: 0.4278 - val_accuracy: 0.8102\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 33s 172ms/step - loss: 0.3576 - accuracy: 0.8507 - val_loss: 0.4394 - val_accuracy: 0.8188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6def946d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeB9226k5fo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a49b93a4-b4bc-458f-d7e8-284881aa4a43"
      },
      "source": [
        "preds = m.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 746\n",
            "Falsos Negativos: 168\n",
            "Verdaderos Positivos: 501\n",
            "Falsos Positivos: 108\n",
            "\n",
            "precision score: 0.8226600985221675\n",
            "recall score: 0.7488789237668162\n",
            "f1 score: 0.7840375586854461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjt9H6pW5owl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "59061514-8aa3-4e78-e14a-edc540174e22"
      },
      "source": [
        "m.fit(padded_vecs_train, train_target, epochs=epochs)\n",
        "k_preds = m.predict_classes(padded_vecs_test)\n",
        "\n",
        "results = df_test[['id']]\n",
        "results['target'] = k_preds\n",
        "results.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "238/238 [==============================] - 36s 151ms/step - loss: 0.1899 - accuracy: 0.9246\n",
            "Epoch 2/5\n",
            "238/238 [==============================] - 38s 162ms/step - loss: 0.1743 - accuracy: 0.9343\n",
            "Epoch 3/5\n",
            "238/238 [==============================] - 37s 154ms/step - loss: 0.1682 - accuracy: 0.9320\n",
            "Epoch 4/5\n",
            "238/238 [==============================] - 37s 155ms/step - loss: 0.1587 - accuracy: 0.9377\n",
            "Epoch 5/5\n",
            "238/238 [==============================] - 38s 158ms/step - loss: 0.1365 - accuracy: 0.9436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3263, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j906xVI564Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.to_csv('lstm-v2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0daMiAK65LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}