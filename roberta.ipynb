{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roberta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK32y67VVXfi",
        "colab_type": "text"
      },
      "source": [
        "# RoBERTa\n",
        "\n",
        "En este notebook vamos a utilizar una versión alternativa de BERT llamada RoBERTa la cual se supone que es aún más potente.\n",
        "\n",
        "La idea va a ser utilizar RoBERTa para crear embeddings para los tweets como ya veníamos haciendo, y pasar esto por los siguientes modelos:\n",
        "\n",
        "* Una CNN con tres filtros de distinto tamaño, la cual utilizamos anteriormente con otros embeddings.\n",
        "\n",
        "* Una RNN sencilla como la que se encuentra en el notebook `lstm-baseline`.\n",
        "\n",
        "También vamos a probar utilizar las features que extrae la capa densa de ambos modelos para usarlas como input en una SVM, lo cual parece dar buenos resultados para este problema en particular.\n",
        "\n",
        "Finalmente vamos a hacer un pseudo ensamble haciendo un averaging entre las predicciones de las dos redes descriptas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Upo6Pc9S0Ne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "ba05499e-9655-48ed-8259-d05db311b399"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP91PCYhS1ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import int32\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "from sklearn import svm\n",
        "from keras.layers import Dense, Dropout, Input, GlobalMaxPooling1D, Conv1D, concatenate, LSTM\n",
        "from keras.models import  Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cogCNaPiTAYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics(predictions, y_test):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
        "    print(f'Verdaderos Negativos: {tn}')\n",
        "    print(f'Falsos Negativos: {fn}')\n",
        "    print(f'Verdaderos Positivos: {tp}')\n",
        "    print(f'Falsos Positivos: {fp}')\n",
        "    print()\n",
        "    print(f'precision score: {precision_score(y_test, predictions)}')\n",
        "    print(f'recall score: {recall_score(y_test, predictions)}')\n",
        "    print(f'f1 score: {f1_score(y_test,  predictions)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQGTx7z2Niep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Créditos a este notebook https://www.kaggle.com/nmaguette/up-to-date-list-of-slangs-for-text-preprocessing\n",
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}\n",
        "\n",
        "\n",
        "def convert_abbrev(word):\n",
        "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
        "\n",
        "# Esta lista de contractions la obtuvimos de un notebook de Kaggle también, el cual pone como fuente al siguiente\n",
        "# post de stackoverflow http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"needn't\": \"need not\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who's\": \"who is\",\n",
        "\"won't\": \"will not\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\",\n",
        "\"thx\"   : \"thanks\",\n",
        "\"didnt\" : \"did not\"\n",
        "}\n",
        "\n",
        "\n",
        "def remove_contractions(text):\n",
        "    return contractions[text.lower()] if text.lower() in contractions.keys() else text\n",
        "\n",
        "def clean_text(text):\n",
        "    words = text.split(' ')\n",
        "    words = [convert_abbrev(word) for word in words]\n",
        "    words = [remove_contractions(word) for word in words]\n",
        "    text = ' '.join([word for word in words if not word.startswith('@')])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGUdR-deTFHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/fsicardir/datos-tp2/master/dataset/train.csv?token=AFVAIUVCNNLG2DE4LNMEN2C7HMHQE'\n",
        "url_test = 'https://raw.githubusercontent.com/fsicardir/datos-tp2/master/dataset/test.csv?token=AFVAIUWNQDPWBVOREJGS2727HMHPG'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)\n",
        "\n",
        "# Quitamos las urls\n",
        "df_train['text'] = df_train['text'].str.replace(r'http:\\/\\/.*', '', regex=True).replace(r'https:\\/\\/.*', '', regex=True)\n",
        "df_test['text'] = df_test['text'].str.replace(r'http:\\/\\/.*', '', regex=True).replace(r'https:\\/\\/.*', '', regex=True)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(clean_text)\n",
        "df_test['text'] = df_test['text'].apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldlPstWKTIq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "train_text = np.array([tokenizer.encode(text,\n",
        "                                     add_special_tokens=True, \n",
        "                                     max_length=40, truncation=True,\n",
        "                                     pad_to_max_length=True) for text in df_train[\"text\"]])\n",
        "\n",
        "test_text = np.array([tokenizer.encode(text, \n",
        "                           add_special_tokens=True, \n",
        "                           max_length=40, truncation=True, \n",
        "                           pad_to_max_length=True) for text in df_test[\"text\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvwPVsIOmut9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27619ddc-1c88-49b6-80f1-6baf87134770"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_text, df_train.target, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6090, 40), (1523, 40), (6090,), (1523,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an11EntfnQHV",
        "colab_type": "text"
      },
      "source": [
        "# RoBERTa + CNN con múltiples filtros\n",
        "\n",
        "Esta red es la misma que utilizamos en otro notebook y nos dio resultados aceptables, veamos si con RoBERTa detrás es capaz de más."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_8rXVDeTvYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "6c391cf8-79e0-4372-e48c-4029cabf0845"
      },
      "source": [
        "inputs = Input((40,), dtype=int32)\n",
        "roberta_pretrained = TFRobertaModel.from_pretrained('roberta-base')\n",
        "sequence, cls = roberta_pretrained(inputs)\n",
        "\n",
        "conv1 = Conv1D(128, kernel_size=3, activation='relu', name='conv_size_3')(sequence)\n",
        "conv1 = GlobalMaxPooling1D()(conv1)\n",
        "\n",
        "conv2 = Conv1D(128, kernel_size=4, activation='relu', name='conv_size_4')(sequence)\n",
        "conv2 = GlobalMaxPooling1D()(conv2)\n",
        "\n",
        "conv3 = Conv1D(128, kernel_size=2, activation='relu', name='conv_size_2')(sequence)\n",
        "conv3 = GlobalMaxPooling1D()(conv3)\n",
        "\n",
        "pooling = concatenate([conv1, conv2, conv3])\n",
        "\n",
        "dense = Dense(64, activation='relu', name='dense_layer')(pooling)\n",
        "dense = Dropout(0.5)(dense)\n",
        "\n",
        "predictions = Dense(1, activation=\"sigmoid\", name=\"predictions\")(dense)\n",
        "model = Model(inputs, predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss=\"binary_crossentropy\",  metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6_oDAKiUGfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "738e26d9-0d0a-47d2-a642-e904a04f316d"
      },
      "source": [
        "def rate(epoch):\n",
        "    return 1.5e-5/(epoch + 1)\n",
        "\n",
        "scheduler = LearningRateScheduler(rate)\n",
        "EPOCHS = 3\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[scheduler], epochs=EPOCHS, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_6/roberta/pooler/dense/kernel:0', 'tf_roberta_model_6/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_6/roberta/pooler/dense/kernel:0', 'tf_roberta_model_6/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_6/roberta/pooler/dense/kernel:0', 'tf_roberta_model_6/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_6/roberta/pooler/dense/kernel:0', 'tf_roberta_model_6/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "191/191 [==============================] - 64s 334ms/step - loss: 0.5523 - accuracy: 0.7228 - val_loss: 0.4880 - val_accuracy: 0.8083\n",
            "Epoch 2/3\n",
            "191/191 [==============================] - 61s 318ms/step - loss: 0.4260 - accuracy: 0.8207 - val_loss: 0.4137 - val_accuracy: 0.8332\n",
            "Epoch 3/3\n",
            "191/191 [==============================] - 61s 318ms/step - loss: 0.3879 - accuracy: 0.8319 - val_loss: 0.3931 - val_accuracy: 0.8444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b414GJqjUOL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "13c075d4-d1b4-4df9-ccd8-9d85892da646"
      },
      "source": [
        "preds = model.predict(X_test)\n",
        "\n",
        "preds = [1 if x >= 0.5 else 0 for x in preds]\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 783\n",
            "Falsos Negativos: 146\n",
            "Verdaderos Positivos: 503\n",
            "Falsos Positivos: 91\n",
            "\n",
            "precision score: 0.8468013468013468\n",
            "recall score: 0.7750385208012327\n",
            "f1 score: 0.8093322606596943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WfmbsNvlVoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = model.predict(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYKe05aPBb9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = [1 if x >= 0.5 else 0 for x in test_preds]\n",
        "\n",
        "df_test['target'] = test_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0migzHQLB52o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test[['id', 'target']].to_csv('roberta-cnn-multi-filter.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhimSdBEsmK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Guardamos los pesos del modelo porque me gustó su performance.\n",
        "model.save_weights('roberta-cnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sPng97XX6EC",
        "colab_type": "text"
      },
      "source": [
        "# SVM con features extraídas por la CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6dgxj1rCBcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extractor = Model(inputs, model.get_layer('dense_layer').output)\n",
        "features_train = extractor.predict(X_train)\n",
        "features_val = extractor.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Bx1mUtH4fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svc = svm.SVC(probability=True, C=0.5, random_state=42)\n",
        "\n",
        "svc.fit(features_train, y_train)\n",
        "\n",
        "svc_preds = svc.predict(features_val)\n",
        "metrics(svc_preds, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDtre7_zIUkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = extractor.predict(test_text)\n",
        "kaggle_preds = svc.predict(test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCZuZZFoxmT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['target'] = kaggle_preds\n",
        "df_test[['id', 'target']].to_csv('roberta-cnn-multi-filter-into-svc.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4rsdI1H6NLQ",
        "colab_type": "text"
      },
      "source": [
        "# RoBERTa + LSTM Simple\n",
        "\n",
        "Probamos sin `return_sequences=True` y dio peores resultados.\n",
        "\n",
        "Así que utilizamos el max pooling para planchar el output de la capa LSTM, y obtuvimos resultados decentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCIyMViHHOGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "98910e53-9560-472e-a372-9a85b13aa9d6"
      },
      "source": [
        "input_ids = Input((40,), dtype=int32)\n",
        "roberta_pretrained = TFRobertaModel.from_pretrained('roberta-base')\n",
        "sequence, cls = roberta_pretrained(input_ids)\n",
        "\n",
        "lstm = LSTM(units=128, return_sequences=True)(sequence)\n",
        "lstm = GlobalMaxPooling1D()(lstm)\n",
        "dense = Dense(32, activation='relu', name='dense_layer')(lstm)\n",
        "dense = Dropout(0.5)(dense)\n",
        "predictions = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "model_lstm = Model(input_ids, predictions)\n",
        "model_lstm.compile(optimizer='adam', loss=\"binary_crossentropy\",  metrics=[\"accuracy\"])\n",
        "model_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 40)]              0         \n",
            "_________________________________________________________________\n",
            "tf_roberta_model_5 (TFRobert ((None, 40, 768), (None,  124645632 \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 40, 128)           459264    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer (Dense)          (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_233 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 125,109,057\n",
            "Trainable params: 125,109,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBuUf8a38QE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "cce212fc-add2-41de-95c9-1f3c467a627d"
      },
      "source": [
        "# Probamos con 2.5e-5,  0.5e-5 y 3.5e-5 pero no superaron a este valor.\n",
        "def rate(epoch):\n",
        "    return 1.5e-5/(epoch + 1)\n",
        "\n",
        "# Actualiza el learning rate del optimizador al inicio de cada epoch.\n",
        "scheduler = LearningRateScheduler(rate)\n",
        "EPOCHS = 3\n",
        "history = model_lstm.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[scheduler], epochs=EPOCHS, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_5/roberta/pooler/dense/kernel:0', 'tf_roberta_model_5/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_5/roberta/pooler/dense/kernel:0', 'tf_roberta_model_5/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_5/roberta/pooler/dense/kernel:0', 'tf_roberta_model_5/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_5/roberta/pooler/dense/kernel:0', 'tf_roberta_model_5/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "191/191 [==============================] - 64s 333ms/step - loss: 0.5284 - accuracy: 0.7527 - val_loss: 0.3950 - val_accuracy: 0.8378\n",
            "Epoch 2/3\n",
            "191/191 [==============================] - 60s 316ms/step - loss: 0.4017 - accuracy: 0.8365 - val_loss: 0.3865 - val_accuracy: 0.8391\n",
            "Epoch 3/3\n",
            "191/191 [==============================] - 60s 315ms/step - loss: 0.3652 - accuracy: 0.8583 - val_loss: 0.3740 - val_accuracy: 0.8555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE-YMp698XaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "674aecdd-49d2-4574-aa3a-f2671384ac16"
      },
      "source": [
        "preds = model_lstm.predict(X_test)\n",
        "\n",
        "preds = [1 if x >= 0.5 else 0 for x in preds]\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 817\n",
            "Falsos Negativos: 163\n",
            "Verdaderos Positivos: 486\n",
            "Falsos Positivos: 57\n",
            "\n",
            "precision score: 0.8950276243093923\n",
            "recall score: 0.74884437596302\n",
            "f1 score: 0.8154362416107384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEjf9SZNF0hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = model_lstm.predict(test_text)\n",
        "test_preds = [1 if x >= 0.5 else 0 for x in test_preds]\n",
        "\n",
        "df_test['target'] = test_preds\n",
        "df_test[['id', 'target']].to_csv('roberta-lstm.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoeaePzIo_Uf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Guardamos los pesos del modelo porque me gustó su performance.\n",
        "model_lstm.save_weights('roberta-lstm.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7bGZOJUociN",
        "colab_type": "text"
      },
      "source": [
        "# Probamos utilizar SVC con las features extraídas por el modelo anterior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ootlvxnZbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extractor = Model(input_ids, model_lstm.get_layer('dense_layer').output)\n",
        "features_train = extractor.predict(X_train)\n",
        "features_val = extractor.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIPaXSgnxUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "70567ecc-e11d-4750-af4d-cd2ba6f53857"
      },
      "source": [
        "svc = svm.SVC(probability=True, C=0.5, random_state=42)\n",
        "\n",
        "svc.fit(features_train, y_train)\n",
        "\n",
        "svc_preds = svc.predict(features_val)\n",
        "metrics(svc_preds, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 807\n",
            "Falsos Negativos: 158\n",
            "Verdaderos Positivos: 491\n",
            "Falsos Positivos: 67\n",
            "\n",
            "precision score: 0.8799283154121864\n",
            "recall score: 0.7565485362095532\n",
            "f1 score: 0.8135874067937034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8sRLrDhn4Ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_features = extractor.predict(test_text)\n",
        "kaggle_preds = svc.predict(test_features)\n",
        "df_test['target'] = kaggle_preds\n",
        "df_test[['id', 'target']].to_csv('roberta-lstm-into-svc.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioEmbRkRohj7",
        "colab_type": "text"
      },
      "source": [
        "# Averaging entre CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsHaRQYZpZCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_preds = model.predict(test_text)\n",
        "lstm_preds = model_lstm.predict(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Qa1zo8qh7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_preds = []\n",
        "for x, y in zip(cnn_preds, lstm_preds):\n",
        "  final_preds.append(x * 0.4 + y * 0.6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sji5lauKrwox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d315b41-7c38-4b2e-d15c-af50501fa944"
      },
      "source": [
        "final_preds = [1 if x >= 0.5 else 0 for x in final_preds]\n",
        "final_preds[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jkGn66BrxJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['target'] = final_preds\n",
        "df_test[['id', 'target']].to_csv('roberta-cnn-lstm-avg.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpnmudCesLNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}