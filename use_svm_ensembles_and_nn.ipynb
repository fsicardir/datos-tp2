{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use-svm-ensembles-and-nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOHBLRCgJ2kX5xY+2IBBnF5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuNtIsyh2J5e",
        "colab_type": "text"
      },
      "source": [
        "# Universal Sentence Encoder + clasificadores\n",
        "\n",
        "Paper https://arxiv.org/pdf/1803.11175.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9H9XtrvYEc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import tensorflow_hub as hub \n",
        "from keras.layers import Dense, Dropout, Input, Lambda, SpatialDropout1D\n",
        "from keras.models import  Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import string"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjuO0KXQA3jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics(predictions, y_test):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
        "    print(f'Verdaderos Negativos: {tn}')\n",
        "    print(f'Falsos Negativos: {fn}')\n",
        "    print(f'Verdaderos Positivos: {tp}')\n",
        "    print(f'Falsos Positivos: {fp}')\n",
        "    print()\n",
        "    print(f'precision score: {precision_score(y_test, predictions)}')\n",
        "    print(f'recall score: {recall_score(y_test, predictions)}')\n",
        "    print(f'f1 score: {f1_score(y_test,  predictions)}')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iKmMVwiYeZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargamos USE\n",
        "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder-large/5')\n",
        "\n",
        "# Obtenemos el embedding correspondiente para el tweet\n",
        "def transform(text):\n",
        "    vectors = [tf.reshape(embed([line]), [-1]).numpy() for line in text]\n",
        "    return vectors"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQGTx7z2Niep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Créditos a este notebook https://www.kaggle.com/nmaguette/up-to-date-list-of-slangs-for-text-preprocessing\n",
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\", \n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\", \n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\", \n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "    \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\", \n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}\n",
        "\n",
        "\n",
        "def convert_abbrev(word):\n",
        "    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n",
        "\n",
        "# Esta lista de contractions la obtuvimos de un notebook de Kaggle también, el cual pone como fuente al siguiente\n",
        "# post de stackoverflow http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"needn't\": \"need not\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who's\": \"who is\",\n",
        "\"won't\": \"will not\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\",\n",
        "\"thx\"   : \"thanks\",\n",
        "\"didnt\" : \"did not\"\n",
        "}\n",
        "\n",
        "\n",
        "def remove_contractions(text):\n",
        "    return contractions[text.lower()] if text.lower() in contractions.keys() else text\n",
        "\n",
        "def clean_text(text):\n",
        "    words = text.lower().split(' ')\n",
        "    words = [convert_abbrev(word) for word in words]\n",
        "    words = [remove_contractions(word) for word in words]\n",
        "    text = ' '.join([word for word in words if not word.startswith('@')])\n",
        "    return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCsAjaDPYt1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/fsicardir/datos-tp2/master/dataset/train.csv?token=AFVAIUVCNNLG2DE4LNMEN2C7HMHQE'\n",
        "url_test = 'https://raw.githubusercontent.com/fsicardir/datos-tp2/master/dataset/test.csv?token=AFVAIUWNQDPWBVOREJGS2727HMHPG'\n",
        "\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_test = pd.read_csv(url_test)\n",
        "\n",
        "# Quitamos las urls\n",
        "df_train['text'] = df_train['text'].str.replace(r'http:\\/\\/.*', '', regex=True).replace(r'https:\\/\\/.*', '', regex=True)\n",
        "df_test['text'] = df_test['text'].str.replace(r'http:\\/\\/.*', '', regex=True).replace(r'https:\\/\\/.*', '', regex=True)\n",
        "\n",
        "# Con las keywords concatenadas no dio mejor resultado.\n",
        "# df_train['keyword'].fillna(\"unknown\", inplace=True)\n",
        "# df_test['keyword'].fillna(\"unknown\", inplace=True)\n",
        "# df_train['keyword'] = df_train['keyword'].apply(lambda x: x.replace(\"%20\", \" \"))\n",
        "# df_test['keyword'] = df_test['keyword'].apply(lambda x: x.replace(\"%20\", \" \"))\n",
        "\n",
        "# df_train['text'] = df_train['text'] + df_train['keyword']\n",
        "# df_test['text'] = df_test['text'] + df_test['keyword']\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(clean_text)\n",
        "df_test['text'] = df_test['text'].apply(clean_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDo5ZFReBqEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors_train = transform(df_train.text)\n",
        "vectors_test = transform(df_test.text)\n",
        "# Con random_state=1337 da .81 de f1 score.\n",
        "# El submit de kaggle que dio 0.83 fue hecho con random_state=42 y sin limpiar los datos, ni siquiera URLs!"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BedwrV_Uc9RO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(vectors_train, df_train.target, test_size=0.2, random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9f1E2XjYmbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "fb6b8784-ee98-4d78-b397-7a341964f54c"
      },
      "source": [
        "svc = svm.SVC(random_state=42)\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "preds = svc.predict(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 801\n",
            "Falsos Negativos: 173\n",
            "Verdaderos Positivos: 476\n",
            "Falsos Positivos: 73\n",
            "\n",
            "precision score: 0.8670309653916212\n",
            "recall score: 0.7334360554699538\n",
            "f1 score: 0.7946577629382304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aZIxu-3c_Uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle_preds = svc.predict(vectors_test)\n",
        "df_test['target'] = kaggle_preds\n",
        "df_test[['id', 'target']].to_csv('use-svm-clean-text.csv', index=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJjCBZbw4CYs",
        "colab_type": "text"
      },
      "source": [
        "# Probemos utilizar KNN y otros clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u4c3l8Q4Sw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "43ffb266-e776-47db-f25e-8018685e5885"
      },
      "source": [
        "knn = KNeighborsClassifier()\n",
        "params = {\n",
        "    'n_neighbors': [5, 25, 50],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "grid_knn = GridSearchCV(knn, param_grid=params, n_jobs=-1, cv=5)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "knn_preds = grid_knn.predict(X_test)\n",
        "metrics(knn_preds, y_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 693\n",
            "Falsos Negativos: 128\n",
            "Verdaderos Positivos: 521\n",
            "Falsos Positivos: 181\n",
            "\n",
            "precision score: 0.7421652421652422\n",
            "recall score: 0.802773497688752\n",
            "f1 score: 0.771280532938564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Am8ppPA4abY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "4909ed6b-2fe3-430b-a5fa-e5c5c2692ff6"
      },
      "source": [
        "regr = LogisticRegression(max_iter=1000)\n",
        "params = {\n",
        "    'C': [0.001,0.01,0.1,1,10,100,1000]\n",
        "}\n",
        "grid_regr = GridSearchCV(regr, param_grid=params)\n",
        "grid_regr.fit(X_train, y_train)\n",
        "regr_preds = grid_regr.predict(X_test)\n",
        "metrics(regr_preds, y_test)\n",
        "grid_regr.best_params_"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 778\n",
            "Falsos Negativos: 167\n",
            "Verdaderos Positivos: 482\n",
            "Falsos Positivos: 96\n",
            "\n",
            "precision score: 0.8339100346020761\n",
            "recall score: 0.7426810477657936\n",
            "f1 score: 0.7856560717196415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS7lsbPUbXSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "91c50e74-f637-4ac9-87fc-ec181bbe866e"
      },
      "source": [
        "ridge = RidgeClassifier(alpha=12, solver='saga')\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_preds = ridge.predict(X_test)\n",
        "metrics(ridge_preds, y_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 778\n",
            "Falsos Negativos: 176\n",
            "Verdaderos Positivos: 473\n",
            "Falsos Positivos: 96\n",
            "\n",
            "precision score: 0.8312829525483304\n",
            "recall score: 0.7288135593220338\n",
            "f1 score: 0.7766830870279147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ0tVF9yLWMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vcf = VotingClassifier(estimators=[('svc', svc), ('knn', grid_knn.best_estimator_),\n",
        "                                   ('lr', grid_regr.best_estimator_), ('ridge', ridge)], weights=[2, 1, 1, 1])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-BDXR-kaoaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "0f3d2b2e-6e25-4895-9207-88c681f6d097"
      },
      "source": [
        "vcf.fit(X_train, y_train)\n",
        "vcf_preds = vcf.predict(X_test)\n",
        "metrics(vcf_preds, y_test)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 789\n",
            "Falsos Negativos: 166\n",
            "Verdaderos Positivos: 483\n",
            "Falsos Positivos: 85\n",
            "\n",
            "precision score: 0.8503521126760564\n",
            "recall score: 0.7442218798151001\n",
            "f1 score: 0.7937551355792933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDWkLrR_ayxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.82 en Kaggle :()\n",
        "kaggle_preds = vcf.predict(vectors_test)\n",
        "df_test['target'] = kaggle_preds\n",
        "df_test[['id', 'target']].to_csv('use-ensemble.csv', index=False)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aBYGlOE7CdS",
        "colab_type": "text"
      },
      "source": [
        "# NN\n",
        "\n",
        "Vamos a intentar usar una red neuronal tradicional de dos capas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB-PxOIrC5EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_train.text, df_train.target, test_size=0.2, random_state=1337)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EACdEk4RIb-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "904f742c-2e49-43ca-d7b2-0f307a99441b"
      },
      "source": [
        "DROPOUT_RATE = 0.5\n",
        "NEURONS = 128\n",
        "# Mejor resultado hasta ahora con dos capas densas de 128 neuronas y dropout 0.5\n",
        "input = Input(shape=[], dtype=tf.string)\n",
        "embedding = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder-large/5', \n",
        "                    trainable=False)(input)\n",
        "dense = Dense(NEURONS, activation='relu')(embedding)\n",
        "dense = Dropout(DROPOUT_RATE)(dense)\n",
        "dense = Dense(NEURONS, activation='relu', name='output_for_svc')(dense)\n",
        "dense = Dropout(DROPOUT_RATE)(dense)                   \n",
        "prediction = Dense(1, activation='sigmoid')(dense)\n",
        "model = Model(input, prediction)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "keras_layer (KerasLayer)     (None, 512)               147354880 \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output_for_svc (Dense)       (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 147,437,185\n",
            "Trainable params: 82,305\n",
            "Non-trainable params: 147,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LE7NUq1Cpqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "e66ca904-e31c-4a61-a571-321d82ba4c6d"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "epochs = 10\n",
        "model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=[es])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "191/191 [==============================] - 101s 527ms/step - loss: 0.5291 - accuracy: 0.7381 - val_loss: 0.4092 - val_accuracy: 0.8227\n",
            "Epoch 2/10\n",
            "191/191 [==============================] - 95s 500ms/step - loss: 0.4104 - accuracy: 0.8236 - val_loss: 0.3952 - val_accuracy: 0.8299\n",
            "Epoch 3/10\n",
            "191/191 [==============================] - 97s 509ms/step - loss: 0.3935 - accuracy: 0.8300 - val_loss: 0.3928 - val_accuracy: 0.8418\n",
            "Epoch 4/10\n",
            "191/191 [==============================] - 95s 496ms/step - loss: 0.3637 - accuracy: 0.8460 - val_loss: 0.3943 - val_accuracy: 0.8418\n",
            "Epoch 5/10\n",
            "191/191 [==============================] - 95s 495ms/step - loss: 0.3468 - accuracy: 0.8548 - val_loss: 0.4041 - val_accuracy: 0.8404\n",
            "Epoch 6/10\n",
            "191/191 [==============================] - 94s 494ms/step - loss: 0.3238 - accuracy: 0.8657 - val_loss: 0.4069 - val_accuracy: 0.8404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7656789d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYQEzc3PHpfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "544f6a4f-d5c0-4218-ae6d-0ef8a2eddf68"
      },
      "source": [
        "nn_preds = model.predict(X_test)\n",
        "nn_preds = [1 if x >= 0.5 else 0 for x in nn_preds]\n",
        "metrics(nn_preds, y_test)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 790\n",
            "Falsos Negativos: 174\n",
            "Verdaderos Positivos: 490\n",
            "Falsos Positivos: 69\n",
            "\n",
            "precision score: 0.8765652951699463\n",
            "recall score: 0.7379518072289156\n",
            "f1 score: 0.8013082583810303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMssKLRgyPRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_kaggle_preds = model.predict(df_test.text)\n",
        "df_test['target'] = [1 if x >= 0.5 else 0 for x in nn_kaggle_preds]\n",
        "df_test[['id', 'target']].to_csv('use-nn-v2.csv', index=False)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T2zaEkfg32Z",
        "colab_type": "text"
      },
      "source": [
        "# SVM + NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw4a4euYXNmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extractor = Model(model.inputs, model.get_layer('output_for_svc').output)\n",
        "features_train = extractor.predict(X_train)\n",
        "features_val = extractor.predict(X_test)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIm-qxt4c6F0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "8ba55178-4fcf-4ff3-8927-8743bdaea166"
      },
      "source": [
        "svc_nn = svm.SVC()\n",
        "svc_nn.fit(features_train, y_train)\n",
        "preds = svc_nn.predict(features_val)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verdaderos Negativos: 773\n",
            "Falsos Negativos: 169\n",
            "Verdaderos Positivos: 495\n",
            "Falsos Positivos: 86\n",
            "\n",
            "precision score: 0.8519793459552496\n",
            "recall score: 0.7454819277108434\n",
            "f1 score: 0.7951807228915664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6BKeVLLCsmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save_weights('use-nn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs_ZJXwv_Mog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}